{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tab Scraper\n",
    "---\n",
    "\n",
    "Author: Peter Zhang\n",
    "\n",
    "Scraping tool for Tabroom."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup\n",
    "\n",
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import urllib.request, urllib.parse, urllib.error\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import csv\n",
    "import os.path\n",
    "from os import path\n",
    "import sys\n",
    "from string import ascii_lowercase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Settings\n",
    "\n",
    "- OVERWRITE determines whether or not to update existing files.\n",
    "- PAGES_URL is a list of Wiki pages\n",
    "- OUTPATH is where files are stored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# settings\n",
    "OVERWRITE = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get tournament URLS\n",
    "TOURNAMENT_CSV = 'tools/tourn_info.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outpath\n",
    "OUTPATH = \"tab_data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# equivalent names\n",
    "LD_NAMES = [name.strip() for name in open('tools/ld_eventnames.txt', 'r')]\n",
    "PF_NAMES = [name.strip() for name in open('tools/pf_eventnames.txt', 'r')]\n",
    "CX_NAMES = [name.strip() for name in open('tools/cx_eventnames.txt', 'r')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set events to scrape\n",
    "TARGET_EVENTS = [\"LD\", \"PF\", \"CX\"]\n",
    "def getType(raw_name):\n",
    "    if raw_name in LD_NAMES:\n",
    "        return \"LD\"\n",
    "    if raw_name in PF_NAMES:\n",
    "        return \"PF\"\n",
    "    if raw_name in CX_NAMES:\n",
    "        return \"CX\"\n",
    "    return \"None\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entry Scrapers\n",
    "\n",
    "#### Events\n",
    "\n",
    "Take a tournament ID and get links to events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getEvents(tourn_id):\n",
    "    url = \"https://www.tabroom.com/index/tourn/fields.mhtml?tourn_id=\" + tourn_id\n",
    "    html = urlopen(url).read()\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    links = [link for link in soup.find_all('a') if \"event_id\" in link.get('href')]\n",
    "    return [(link.contents[0].strip(), link.get('href')) for link in links]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Congressional Debate',\n",
       "  '/index/tourn/fields.mhtml?tourn_id=16856&event_id=141000'),\n",
       " ('JV LD', '/index/tourn/fields.mhtml?tourn_id=16856&event_id=141001'),\n",
       " ('Novice LD', '/index/tourn/fields.mhtml?tourn_id=16856&event_id=141003'),\n",
       " ('Novice Public Forum',\n",
       "  '/index/tourn/fields.mhtml?tourn_id=16856&event_id=141004'),\n",
       " ('Varsity LD', '/index/tourn/fields.mhtml?tourn_id=16856&event_id=141005'),\n",
       " ('Varsity Public Forum',\n",
       "  '/index/tourn/fields.mhtml?tourn_id=16856&event_id=141006')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getURLs(\"16856\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Entries\n",
    "\n",
    "Take the URL to an event's page and return event entry info."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract table from a page\n",
    "def getEntries(url, eventType, tournName):\n",
    "    \n",
    "    html = urlopen(url).read()\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "    table = soup.find(\"table\").find(\"tbody\")\n",
    "    \n",
    "    entries = []\n",
    "    for row in table.find_all(\"tr\"):\n",
    "        \n",
    "        entries.append([tournName, eventType] + [field.text.strip() for field in row.find_all(\"td\")])\n",
    "    \n",
    "    return entries\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Acton-Boxborough Regional High Scho',\n",
       "  'MA/US',\n",
       "  'Bellerina Hu',\n",
       "  'Acton-Boxborough BH',\n",
       "  'LD'],\n",
       " ['Apple Valley High School',\n",
       "  'MN/US',\n",
       "  'John Schwartz',\n",
       "  'Apple Valley JS',\n",
       "  'LD'],\n",
       " ['Apple Valley High School',\n",
       "  'MN/US',\n",
       "  'Nora Bolsoni',\n",
       "  'Apple Valley NB',\n",
       "  'LD'],\n",
       " ['Appleton North', 'WI/US', 'Mihir Uberoi', 'Appleton North MU', 'LD'],\n",
       " ['BASIS Independent Silicon Valley In',\n",
       "  'CA/US',\n",
       "  'Shreyas Kapavarapu',\n",
       "  'BASIS Independent Silicon Valley Independent SK',\n",
       "  'LD'],\n",
       " ['Bergen County Academies',\n",
       "  'NJ/US',\n",
       "  'Andrew Kim',\n",
       "  'Bergen County Academies AK',\n",
       "  'LD'],\n",
       " ['Bettendorf High School', 'IA/US', 'Noah Rantilla', 'Bettendorf NR', 'LD'],\n",
       " ['Brentwood School', 'CA/US', 'Sophie Rubin', 'Brentwood SR', 'LD'],\n",
       " ['Byram Hills High School',\n",
       "  'NY/US',\n",
       "  'Eleanor Wangensteen',\n",
       "  'Byram Hills EW',\n",
       "  'LD'],\n",
       " ['Byram Hills High School',\n",
       "  'NY/US',\n",
       "  'Magdalena Whelley',\n",
       "  'Byram Hills MW',\n",
       "  'LD'],\n",
       " ['Byram Hills High School', 'NY/US', 'Sam Hadiono', 'Byram Hills SH', 'LD'],\n",
       " ['Carmel Valley Independent',\n",
       "  'CA/US',\n",
       "  'Andrew Kang',\n",
       "  'Carmel Valley Independent AK',\n",
       "  'LD'],\n",
       " ['Carmel Valley Independent',\n",
       "  'CA/US',\n",
       "  'Elaine Dong',\n",
       "  'Carmel Valley Independent ED',\n",
       "  'LD'],\n",
       " ['Carmel Valley Independent',\n",
       "  'CA/US',\n",
       "  'Katie Wang',\n",
       "  'Carmel Valley Independent KW',\n",
       "  'LD'],\n",
       " ['Carmel Valley Independent',\n",
       "  'CA/US',\n",
       "  'Max Norman',\n",
       "  'Carmel Valley Independent MN',\n",
       "  'LD'],\n",
       " ['Carmel Valley Independent',\n",
       "  'CA/US',\n",
       "  'Sarah Zhou',\n",
       "  'Carmel Valley Independent SZ',\n",
       "  'LD'],\n",
       " ['Carnegie Vanguard High School',\n",
       "  'TX/US',\n",
       "  'Cindy Cui',\n",
       "  'Carnegie Vanguard CC',\n",
       "  'LD'],\n",
       " ['Carnegie Vanguard High School',\n",
       "  'TX/US',\n",
       "  'Leon Sakata',\n",
       "  'Carnegie Vanguard LS',\n",
       "  'LD'],\n",
       " ['Carnegie Vanguard High School',\n",
       "  'TX/US',\n",
       "  'Siddhartha Rana',\n",
       "  'Carnegie Vanguard SR',\n",
       "  'LD'],\n",
       " ['Carnegie Vanguard High School',\n",
       "  'TX/US',\n",
       "  'Tanish Madan',\n",
       "  'Carnegie Vanguard TM',\n",
       "  'LD'],\n",
       " ['Chanhassen High School', 'MN/US', 'Abby Newman', 'Chanhassen AN', 'LD'],\n",
       " ['Coppell High School', 'TX/US', 'Vansh Nanda', 'Coppell VN', 'LD'],\n",
       " ['Coppell High School', 'TX/US', 'Vishal Sivamani', 'Coppell VS', 'LD'],\n",
       " ['Dougherty Valley High School',\n",
       "  'CA/US',\n",
       "  'Arjun Garg',\n",
       "  'Dougherty Valley AG',\n",
       "  'LD'],\n",
       " ['Dougherty Valley High School',\n",
       "  'CA/US',\n",
       "  'Aditya Madaraju',\n",
       "  'Dougherty Valley AM',\n",
       "  'LD'],\n",
       " ['Dougherty Valley High School',\n",
       "  'CA/US',\n",
       "  'Tarpan Mishra',\n",
       "  'Dougherty Valley TM',\n",
       "  'LD'],\n",
       " ['Dowling Catholic High School',\n",
       "  'IA/US',\n",
       "  'James Piazza',\n",
       "  'Dowling Catholic JP',\n",
       "  'LD'],\n",
       " ['Dulles High School', 'TX/US', 'Abhinav Sinha', 'Dulles AS', 'LD'],\n",
       " ['Dulles High School', 'TX/US', 'Connor Self', 'Dulles CS', 'LD'],\n",
       " ['Dulles High School', 'TX/US', 'Rhea Biswas', 'Dulles RB', 'LD'],\n",
       " ['Dulles High School', 'TX/US', 'Sarah Zheng', 'Dulles SZ', 'LD'],\n",
       " ['Dulles High School', 'TX/US', 'Tommy Yu', 'Dulles TY', 'LD'],\n",
       " ['Durham Academy', 'NC/US', 'Aadesh Anchailya', 'Durham AA', 'LD'],\n",
       " ['Durham Academy', 'NC/US', 'Vika Wei', 'Durham VW', 'LD'],\n",
       " ['Dutchtown High School', 'LA/US', 'Harun Vemulapalli', 'Dutchtown HV', 'LD'],\n",
       " ['Eagan High School', 'MN/', 'Ashley Chen', 'Eagan AC', 'LD'],\n",
       " ['Eagan High School', 'MN/', 'Arush Iyer', 'Eagan AI', 'LD'],\n",
       " ['Eagan High School', 'MN/', 'Bianca Turman', 'Eagan BT', 'LD'],\n",
       " ['Eagan High School', 'MN/', 'Julia Schowalter', 'Eagan JS', 'LD'],\n",
       " ['Eagan High School', 'MN/', 'Vrusha Patel', 'Eagan VPa', 'LD'],\n",
       " ['Eastside Independent',\n",
       "  'WA/US',\n",
       "  'Margaret Li',\n",
       "  'Eastside Independent ML',\n",
       "  'LD'],\n",
       " ['Eden Prairie High School', 'MN/US', 'Avik Garg', 'Eden Prairie AGa', 'LD'],\n",
       " ['Edina High School', 'MN/US', 'Ananth Veluvali', 'Edina AV', 'LD'],\n",
       " ['Edina High School', 'MN/US', 'Leo Hickey', 'Edina LH', 'LD'],\n",
       " ['Edina High School', 'MN/US', 'Matt Kumar-Montei', 'Edina MK', 'LD'],\n",
       " ['Elkins High School', 'TX/US', 'Ayush Manoj', 'Elkins AM', 'LD'],\n",
       " ['Evergreen Valley Independent',\n",
       "  'CA/US',\n",
       "  'Saurish Srivastava',\n",
       "  'Evergreen Valley SS',\n",
       "  'LD'],\n",
       " ['Flintridge Preparatory',\n",
       "  'CA/US',\n",
       "  'Thomas Vandenburg',\n",
       "  'Flintridge Prep TV',\n",
       "  'LD'],\n",
       " ['Greenhill School', 'TX/US', 'Arush Adabala', 'Greenhill AA', 'LD'],\n",
       " ['Greenhill School', 'TX/US', 'Krutin Devesh', 'Greenhill KD', 'LD'],\n",
       " ['Greenhill School', 'TX/US', 'Kelly Meng', 'Greenhill KM', 'LD'],\n",
       " ['Greenhill School', 'TX/US', 'Nikitha Thoduguli', 'Greenhill NT', 'LD'],\n",
       " ['Greenhill School', 'TX/US', 'Ramateja Mettu', 'Greenhill RM', 'LD'],\n",
       " ['Greenhill School', 'TX/US', 'Varsha Gande', 'Greenhill VG', 'LD'],\n",
       " ['Hamilton High Independent',\n",
       "  'AZ/US',\n",
       "  'Nolan Burke',\n",
       "  'Hamilton High Independent NB',\n",
       "  'LD'],\n",
       " ['Harrison', 'NY/US', 'Ali Ahmad', 'Harrison AA', 'LD'],\n",
       " ['Harrison', 'NY/US', 'Elizabeth Murno', 'Harrison EM', 'LD'],\n",
       " ['Harrison', 'NY/US', 'Giovanni Cutri', 'Harrison GC', 'LD'],\n",
       " ['Harrison', 'NY/US', 'Mai Blaustein', 'Harrison MB', 'LD'],\n",
       " ['Harrison', 'NY/US', 'Sonali Nicola', 'Harrison SN', 'LD'],\n",
       " ['Hopkins High School', 'MN/US', 'Ezana Tedla', 'Hopkins ET', 'LD'],\n",
       " ['Houston Memorial High School',\n",
       "  'TX/US',\n",
       "  'Daniel Xu',\n",
       "  'Houston Memorial DX',\n",
       "  'LD'],\n",
       " ['Immaculate Heart High School',\n",
       "  'CA/US',\n",
       "  'Beatrice Culligan',\n",
       "  'Immaculate Heart BC',\n",
       "  'LD'],\n",
       " ['Immaculate Heart High School',\n",
       "  'CA/US',\n",
       "  'Felicity Park',\n",
       "  'Immaculate Heart FP',\n",
       "  'LD'],\n",
       " ['Immaculate Heart High School',\n",
       "  'CA/US',\n",
       "  'Jane Lichtman',\n",
       "  'Immaculate Heart JL',\n",
       "  'LD'],\n",
       " ['Immaculate Heart High School',\n",
       "  'CA/US',\n",
       "  'Lucia Botham',\n",
       "  'Immaculate Heart LB',\n",
       "  'LD'],\n",
       " ['Immaculate Heart High School',\n",
       "  'CA/US',\n",
       "  'Riley Rees',\n",
       "  'Immaculate Heart RR',\n",
       "  'LD'],\n",
       " ['Immaculate Heart High School',\n",
       "  'CA/US',\n",
       "  'Zofia Barr',\n",
       "  'Immaculate Heart ZB',\n",
       "  'LD'],\n",
       " ['Iowa City West', 'IA/US', 'Jayden Shin', 'Iowa City West JS', 'LD'],\n",
       " ['Iowa City West', 'IA/US', 'Nathan Weimar', 'Iowa City West NW', 'LD'],\n",
       " ['L C Anderson High School',\n",
       "  'TX/US',\n",
       "  'Aseel Rawashdeh',\n",
       "  'L C Anderson AR',\n",
       "  'LD'],\n",
       " ['L C Anderson High School', 'TX/US', 'Brett Cryan', 'L C Anderson BC', 'LD'],\n",
       " ['Lake Highland Preparatory School',\n",
       "  'FL/US',\n",
       "  'Anay Shah',\n",
       "  'Lake Highland Prep AS',\n",
       "  'LD'],\n",
       " ['Lake Highland Preparatory School',\n",
       "  'FL/US',\n",
       "  'Arjun Verma',\n",
       "  'Lake Highland Prep AV',\n",
       "  'LD'],\n",
       " ['Lake Highland Preparatory School',\n",
       "  'FL/US',\n",
       "  'Dylan Pandya',\n",
       "  'Lake Highland Prep DP',\n",
       "  'LD'],\n",
       " ['Lake Highland Preparatory School',\n",
       "  'FL/US',\n",
       "  'Krithik Seela',\n",
       "  'Lake Highland Prep KS',\n",
       "  'LD'],\n",
       " ['Lake Highland Preparatory School',\n",
       "  'FL/US',\n",
       "  'Yash Agrawal',\n",
       "  'Lake Highland Prep YA',\n",
       "  'LD'],\n",
       " ['Legacy Christian Academy',\n",
       "  'TX/US',\n",
       "  'Breigh Plat',\n",
       "  'Legacy Christian BP',\n",
       "  'LD'],\n",
       " ['Lexington HS', 'MA/US', 'Archit Kumar', 'Lexington AKu', 'LD'],\n",
       " ['Lexington HS', 'MA/US', 'Anuka Manghwani', 'Lexington AMa', 'LD'],\n",
       " ['Lexington HS', 'MA/US', 'Aavedon Roy', 'Lexington AR', 'LD'],\n",
       " ['Lexington HS', 'MA/US', 'Brett Fortier', 'Lexington BF', 'LD'],\n",
       " ['Lexington HS', 'MA/US', 'Christian Han', 'Lexington CH', 'LD'],\n",
       " ['Lexington HS', 'MA/US', 'Jeong-Wan Choi', 'Lexington JC', 'LD'],\n",
       " ['Lexington HS', 'MA/US', 'Mahad Sohail', 'Lexington MS', 'LD'],\n",
       " ['Lexington HS', 'MA/US', 'Vikrant Maan', 'Lexington VM', 'LD'],\n",
       " ['Lincoln East High School',\n",
       "  'NE/US',\n",
       "  'Elena Belashchenko',\n",
       "  'Lincoln East EB',\n",
       "  'LD'],\n",
       " ['Lincoln East High School',\n",
       "  'NE/US',\n",
       "  'Pratham Soni',\n",
       "  'Lincoln East PS',\n",
       "  'LD'],\n",
       " ['Loyola High School', 'CA/US', 'Benjamin Cortez', 'Loyola BC', 'LD'],\n",
       " ['Loyola High School', 'CA/US', 'Braden Masih', 'Loyola BM', 'LD'],\n",
       " ['Loyola High School', 'CA/US', 'Daniel Beck', 'Loyola DB', 'LD'],\n",
       " ['Loyola High School', 'CA/US', 'Lucas Hunter', 'Loyola LH', 'LD'],\n",
       " ['Loyola High School', 'CA/US', 'Sameer Nayyar', 'Loyola SN', 'LD'],\n",
       " ['Lynbrook HS', 'CA/US', 'Allison Hsu', 'Lynbrook AH', 'LD'],\n",
       " ['Lynbrook HS', 'CA/US', 'Keshav Dandu', 'Lynbrook KD', 'LD'],\n",
       " ['Marlborough School', 'CA/US', 'Eva Rodriguez', 'Marlborough ER', 'LD'],\n",
       " ['Marlborough School', 'CA/US', 'Wyeth Renwick', 'Marlborough WR', 'LD'],\n",
       " ['McNeil High School', 'TX/', 'Anshul Gulati', 'McNeil AG', 'LD'],\n",
       " ['McNeil High School', 'TX/', 'Adrita RayChaudhuri', 'McNeil AR', 'LD'],\n",
       " ['Millard North High School',\n",
       "  'NE/US',\n",
       "  'Nathan Liu',\n",
       "  'Millard North NL',\n",
       "  'LD'],\n",
       " ['Millard North High School',\n",
       "  'NE/US',\n",
       "  'Ryan Lampman',\n",
       "  'Millard North RL',\n",
       "  'LD'],\n",
       " ['Millard North High School', 'NE/US', 'Shiv Lele', 'Millard North SL', 'LD'],\n",
       " ['Milton Academy', 'MA/US', 'Andrew Tsang', 'Milton Acad AT', 'LD'],\n",
       " ['Mission San Jose High School',\n",
       "  'CA/US',\n",
       "  'Advika Bhike',\n",
       "  'Mission San Jose AB',\n",
       "  'LD'],\n",
       " ['Mission San Jose High School',\n",
       "  'CA/US',\n",
       "  'Allison Wang',\n",
       "  'Mission San Jose AW',\n",
       "  'LD'],\n",
       " ['Mission San Jose High School',\n",
       "  'CA/US',\n",
       "  'Sanah Bhardwaj',\n",
       "  'Mission San Jose SB',\n",
       "  'LD'],\n",
       " ['Mission San Jose High School',\n",
       "  'CA/US',\n",
       "  'Shrey Raju',\n",
       "  'Mission San Jose SR',\n",
       "  'LD'],\n",
       " ['Mission San Jose High School',\n",
       "  'CA/US',\n",
       "  'Saranya Singh',\n",
       "  'Mission San Jose SS',\n",
       "  'LD'],\n",
       " ['Murphy Independent', 'TX/US', 'Aadit Walia', 'Murphy Independent AW', 'LD'],\n",
       " ['Needham High School', 'MA/US', 'Vijay Fisch', 'Needham VF', 'LD'],\n",
       " ['New Trier High School', 'IL/US', 'Izaak Van Til', 'New Trier IV', 'LD'],\n",
       " ['North Mecklenburg High School',\n",
       "  'NC/US',\n",
       "  'Patrick Mays',\n",
       "  'North Mecklenburg PM',\n",
       "  'LD'],\n",
       " ['Northern Valley HS Independent',\n",
       "  'NJ/US',\n",
       "  'James Song',\n",
       "  'Northern Valley HS Independent JS',\n",
       "  'LD'],\n",
       " ['Northland Christian School',\n",
       "  'TX/US',\n",
       "  'Lilly Broussard',\n",
       "  'Northland Christian LB',\n",
       "  'LD'],\n",
       " ['Northview High School', 'GA/US', 'Sreyaash Das', 'Northview SD', 'LD'],\n",
       " ['Northview High School', 'GA/US', 'Yasmin Shalim', 'Northview YS', 'LD'],\n",
       " ['Olympia HS', 'FL/US', 'Omar Elsakhawy', 'Olympia OE', 'LD'],\n",
       " ['Peninsula High School', 'CA/US', 'Anish Ramireddy', 'Peninsula AR', 'LD'],\n",
       " ['Peninsula High School', 'CA/US', 'Henry Chung', 'Peninsula HC', 'LD'],\n",
       " ['Peninsula High School', 'CA/US', 'Rhys Moon', 'Peninsula RM', 'LD'],\n",
       " ['Peninsula High School', 'CA/US', 'Saul Munn', 'Peninsula SM', 'LD'],\n",
       " ['Plano Independent', 'TX/US', 'Nathan Gong', 'Plano Independent NG', 'LD'],\n",
       " ['Portola High School', 'CA/US', 'Amitoj Singh', 'Portola AS', 'LD'],\n",
       " ['Riverside HS', 'SC/US', 'Kritika Sethi', 'Riverside KS', 'LD'],\n",
       " ['Rosemount Sr High School', 'MN/US', 'Alex Owens', 'Rosemount AO', 'LD'],\n",
       " ['Rosemount Sr High School',\n",
       "  'MN/US',\n",
       "  'Cierra Phillips',\n",
       "  'Rosemount CP',\n",
       "  'LD'],\n",
       " ['Rosemount Sr High School', 'MN/US', 'Tanvi Adige', 'Rosemount TA', 'LD'],\n",
       " ['STA/Vis', 'MN/US', 'Isabel Brandt', 'STA/Vis IB', 'LD'],\n",
       " ['Saratoga HS', 'CA/US', 'Arnav Garg', 'Saratoga AG', 'LD'],\n",
       " ['Scarsdale High School', 'NY/US', 'Bryan Shi', 'Scarsdale BS', 'LD'],\n",
       " ['Scarsdale High School', 'NY/US', 'Caroline Shi', 'Scarsdale CS', 'LD'],\n",
       " ['Scarsdale High School', 'NY/US', 'Jaden Tepper', 'Scarsdale JT', 'LD'],\n",
       " ['Scarsdale High School', 'NY/US', 'Katherine Shi', 'Scarsdale KS', 'LD'],\n",
       " ['Southlake Carroll',\n",
       "  'TX/US',\n",
       "  'Cristina Capriglione',\n",
       "  'Southlake Carroll CC',\n",
       "  'LD'],\n",
       " ['Southlake Carroll', 'TX/US', 'Enya Pinjani', 'Southlake Carroll EP', 'LD'],\n",
       " ['Southlake Carroll',\n",
       "  'TX/US',\n",
       "  'Pranav Kaginele',\n",
       "  'Southlake Carroll PK',\n",
       "  'LD'],\n",
       " ['Southlake Carroll',\n",
       "  'TX/US',\n",
       "  'Samhith Dharani',\n",
       "  'Southlake Carroll SD',\n",
       "  'LD'],\n",
       " ['St Michael Albertville High School',\n",
       "  'MN/US',\n",
       "  'Alexander Boltz',\n",
       "  'St Michael Albertville AB',\n",
       "  'LD'],\n",
       " ['St. Croix Prep', 'MN/US', 'Alexandriana Davis', 'St Croix Prep AD', 'LD'],\n",
       " ['St. Croix Prep', 'MN/US', 'Avery DeWitt', 'St Croix Prep ADe', 'LD'],\n",
       " ['Stanford Online High School',\n",
       "  'CA/US',\n",
       "  'Mahir Bansal',\n",
       "  'Stanford Online MB',\n",
       "  'LD'],\n",
       " ['Strake Jesuit College Preparatory',\n",
       "  'TX/US',\n",
       "  'Ben Erdmann',\n",
       "  'Strake Jesuit  BE',\n",
       "  'LD'],\n",
       " ['Strake Jesuit College Preparatory',\n",
       "  'TX/US',\n",
       "  'Diego Arcos',\n",
       "  'Strake Jesuit  DA',\n",
       "  'LD'],\n",
       " ['Strake Jesuit College Preparatory',\n",
       "  'TX/US',\n",
       "  'Joseph Georges',\n",
       "  'Strake Jesuit  JG',\n",
       "  'LD'],\n",
       " ['Strake Jesuit College Preparatory',\n",
       "  'TX/US',\n",
       "  'JD Kollar',\n",
       "  'Strake Jesuit  JK',\n",
       "  'LD'],\n",
       " ['Strake Jesuit College Preparatory',\n",
       "  'TX/US',\n",
       "  'Jet Sun',\n",
       "  'Strake Jesuit  JS',\n",
       "  'LD'],\n",
       " ['Strake Jesuit College Preparatory',\n",
       "  'TX/US',\n",
       "  'Karan Shah',\n",
       "  'Strake Jesuit  KS',\n",
       "  'LD'],\n",
       " ['Strake Jesuit College Preparatory',\n",
       "  'TX/US',\n",
       "  'Lucas Walker',\n",
       "  'Strake Jesuit  LWa',\n",
       "  'LD'],\n",
       " ['Strake Jesuit College Preparatory',\n",
       "  'TX/US',\n",
       "  'Michael Stuckert',\n",
       "  'Strake Jesuit  MS',\n",
       "  'LD'],\n",
       " ['Strake Jesuit College Preparatory',\n",
       "  'TX/US',\n",
       "  'Vail Chen',\n",
       "  'Strake Jesuit  VC',\n",
       "  'LD'],\n",
       " ['Strake Jesuit College Preparatory',\n",
       "  'TX/US',\n",
       "  'Vratin Mankidy',\n",
       "  'Strake Jesuit  VM',\n",
       "  'LD'],\n",
       " ['Strath Haven', 'PA/US', 'Ava Manaker', 'Strath Haven AM', 'LD'],\n",
       " ['Success Academy HS - Liberal Arts',\n",
       "  'NY/US',\n",
       "  'Silma Bathily',\n",
       "  'Success Academy HS - Liberal Arts SB',\n",
       "  'LD'],\n",
       " ['The Bronx High School Of Science',\n",
       "  'NY/US',\n",
       "  'Dahlia Bekong',\n",
       "  'Bronx Science DB',\n",
       "  'LD'],\n",
       " ['The Bronx High School Of Science',\n",
       "  'NY/US',\n",
       "  'Leo Matthes',\n",
       "  'Bronx Science LM',\n",
       "  'LD'],\n",
       " ['The Bronx High School Of Science',\n",
       "  'NY/US',\n",
       "  'Nicolas Kim',\n",
       "  'Bronx Science NK',\n",
       "  'LD'],\n",
       " ['The Bronx High School Of Science',\n",
       "  'NY/US',\n",
       "  'Yona Litwin',\n",
       "  'Bronx Science YL',\n",
       "  'LD'],\n",
       " ['The Harker School', 'CA/US', 'Anshul Reddy', 'Harker AR', 'LD'],\n",
       " ['The Harker School', 'CA/US', 'Deven Shah', 'Harker DS', 'LD'],\n",
       " ['The Harker School', 'CA/US', 'Rohan Thakur', 'Harker RT', 'LD'],\n",
       " ['The Oxford Academy', 'CA/US', 'Viren Mehta', 'Oxford VM', 'LD'],\n",
       " ['The Quarry Lane School',\n",
       "  'CA/US',\n",
       "  'Mackenzie Davis',\n",
       "  'Quarry Lane MD',\n",
       "  'LD'],\n",
       " ['Thomas Horace Rogers',\n",
       "  'TX/US',\n",
       "  'Justin Wen',\n",
       "  'Thomas Horace Rogers JW',\n",
       "  'LD'],\n",
       " ['Troy Independent', 'CA/US', 'Andrew Park', 'Troy Independent AP', 'LD'],\n",
       " ['West Des Moines Valley High School',\n",
       "  'IA/US',\n",
       "  'Connor Fogarty',\n",
       "  'West Des Moines Valley CF',\n",
       "  'LD'],\n",
       " ['West Des Moines Valley High School',\n",
       "  'IA/US',\n",
       "  'Jalyn Wu',\n",
       "  'West Des Moines Valley JW',\n",
       "  'LD'],\n",
       " ['West Des Moines Valley High School',\n",
       "  'IA/US',\n",
       "  'Kauai Cua',\n",
       "  'West Des Moines Valley KC',\n",
       "  'LD'],\n",
       " ['West Des Moines Valley High School',\n",
       "  'IA/US',\n",
       "  'Michael Meng',\n",
       "  'West Des Moines Valley MM',\n",
       "  'LD'],\n",
       " ['West Des Moines Valley High School',\n",
       "  'IA/US',\n",
       "  'Shreya Joshi',\n",
       "  'West Des Moines Valley SJ',\n",
       "  'LD'],\n",
       " ['West Des Moines Valley High School',\n",
       "  'IA/US',\n",
       "  'Tony Holm',\n",
       "  'West Des Moines Valley TH',\n",
       "  'LD'],\n",
       " ['West High School SLC', 'UT/US', 'Amrita Krishna', 'West HS SLC AK', 'LD'],\n",
       " ['West High School SLC', 'UT/US', 'Henry Zheng', 'West HS SLC HZ', 'LD'],\n",
       " ['Westlake', 'TX/US', 'Anastasia Keeler', 'Westlake AK', 'LD']]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getEntries(\"https://www.tabroom.com/index/tourn/fields.mhtml?tourn_id=16856&event_id=141005\", \"LD\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Info\n",
    "\n",
    "Get a tournament ID and get the tournament info."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getInfo(tourn_id):\n",
    "\n",
    "    url = \"https://www.tabroom.com/index/tourn/index.mhtml?tourn_id=\" + tourn_id\n",
    "\n",
    "    # load page\n",
    "    html = urlopen(url).read()\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "    # find header\n",
    "    header = soup.select('h5')[0].text.strip()\n",
    "    \n",
    "    # get sub-header\n",
    "    year = header.split('—')[0].strip()\n",
    "    location = header.split('—')[1].strip()\n",
    "    if ',' in location:\n",
    "        city = location.split(',')[0].strip()\n",
    "        state = location.split(',')[1].strip()\n",
    "    \n",
    "    else:\n",
    "        city = \"None\"\n",
    "        state = location\n",
    "\n",
    "    # get info box\n",
    "    info = soup.find_all('span', {'class' : 'smaller half'})[0].text\n",
    "    date = ' '.join(info.split())\n",
    "\n",
    "    return [date, year, city, state]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['11/6 to 11/8', '2020', 'NSDA Campus', 'MN/US']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getInfo(\"16856\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Execution\n",
    "\n",
    "Loop through tournaments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking alta17\n",
      "Scraped LD for alta17\n",
      "Scraped PF for alta17\n",
      "Scraped CX for alta17\n",
      "Checking alta18\n",
      "Scraped LD for alta18\n",
      "Scraped PF for alta18\n",
      "Scraped CX for alta18\n",
      "Checking applevalley17\n",
      "Scraped LD for applevalley17\n",
      "Scraped PF for applevalley17\n",
      "Checking applevalley18\n",
      "Scraped LD for applevalley18\n",
      "Scraped PF for applevalley18\n",
      "Checking asu18\n",
      "Scraped LD for asu18\n",
      "Scraped CX for asu18\n",
      "Scraped PF for asu18\n",
      "Checking asu19\n",
      "Scraped LD for asu19\n",
      "Scraped CX for asu19\n",
      "Scraped PF for asu19\n",
      "Checking badgerland17\n",
      "Scraped LD for badgerland17\n",
      "Scraped CX for badgerland17\n",
      "Checking badgerland18\n",
      "Scraped LD for badgerland18\n",
      "Scraped CX for badgerland18\n",
      "Checking bethelpark18\n",
      "Checking bethelpark19\n",
      "Checking blake17\n",
      "Scraped LD for blake17\n",
      "Scraped CX for blake17\n",
      "Checking blake18\n",
      "Scraped LD for blake18\n",
      "Scraped CX for blake18\n",
      "Checking bronx17\n",
      "Scraped LD for bronx17\n",
      "Scraped CX for bronx17\n",
      "Checking bronx18\n",
      "Scraped LD for bronx18\n",
      "Scraped CX for bronx18\n",
      "Checking cal18\n",
      "Scraped LD for cal18\n",
      "Scraped CX for cal18\n",
      "Scraped PF for cal18\n",
      "Checking cal19\n",
      "Scraped LD for cal19\n",
      "Scraped CX for cal19\n",
      "Scraped PF for cal19\n",
      "Checking churchill18\n",
      "Checking churchill19\n",
      "Scraped CX for churchill19\n",
      "Scraped LD for churchill19\n",
      "Scraped PF for churchill19\n",
      "Checking colleyville18\n",
      "Checking colleyville19\n",
      "Scraped CX for colleyville19\n",
      "Scraped LD for colleyville19\n",
      "Scraped PF for colleyville19\n",
      "Checking columbia18\n",
      "Scraped LD for columbia18\n",
      "Checking columbia19\n",
      "Scraped LD for columbia19\n",
      "Checking cps17\n",
      "Checking cps18\n",
      "Checking cypress17\n",
      "Scraped LD for cypress17\n",
      "Scraped CX for cypress17\n",
      "Checking cypress18\n",
      "Scraped LD for cypress18\n",
      "Scraped CX for cypress18\n",
      "Checking damus17\n",
      "Scraped LD for damus17\n",
      "Scraped CX for damus17\n",
      "Checking damus18\n",
      "Scraped LD for damus18\n",
      "Scraped CX for damus18\n",
      "Checking dowling17\n",
      "Scraped CX for dowling17\n",
      "Checking dowling18\n",
      "Scraped CX for dowling18\n",
      "Checking durham19\n",
      "Scraped PF for durham19\n",
      "Checking emory18\n",
      "Scraped LD for emory18\n",
      "Checking emory19\n",
      "Scraped LD for emory19\n",
      "Checking glenbrooks17\n",
      "Scraped LD for glenbrooks17\n",
      "Scraped CX for glenbrooks17\n",
      "Scraped PF for glenbrooks17\n",
      "Checking glenbrooks18\n",
      "Scraped LD for glenbrooks18\n",
      "Scraped CX for glenbrooks18\n",
      "Scraped PF for glenbrooks18\n",
      "Checking goldendesert18\n",
      "Scraped PF for goldendesert18\n",
      "Scraped CX for goldendesert18\n",
      "Scraped LD for goldendesert18\n",
      "Checking goldendesert19\n",
      "Scraped PF for goldendesert19\n",
      "Scraped CX for goldendesert19\n",
      "Scraped LD for goldendesert19\n",
      "Checking grapevine17\n",
      "Checking grapevine18\n",
      "Scraped LD for grapevine18\n",
      "Checking greenhill17\n",
      "Scraped LD for greenhill17\n",
      "Scraped CX for greenhill17\n",
      "Checking greenhill18\n",
      "Scraped LD for greenhill18\n",
      "Scraped CX for greenhill18\n",
      "Checking harvard18\n",
      "Scraped LD for harvard18\n",
      "Scraped PF for harvard18\n",
      "Checking harvard19\n",
      "Scraped CX for harvard19\n",
      "Scraped LD for harvard19\n",
      "Scraped PF for harvard19\n",
      "Checking heritage17\n",
      "Scraped LD for heritage17\n",
      "Scraped PF for heritage17\n",
      "Checking heritage18\n",
      "Scraped LD for heritage18\n",
      "Scraped PF for heritage18\n",
      "Checking holycross17\n",
      "Checking holycross18\n",
      "Scraped LD for holycross18\n",
      "Scraped CX for holycross18\n",
      "Checking houston18\n",
      "Scraped LD for houston18\n",
      "Scraped CX for houston18\n",
      "Checking houston19\n",
      "Scraped LD for houston19\n",
      "Scraped CX for houston19\n",
      "Checking hwestlake18\n",
      "Scraped LD for hwestlake18\n",
      "Checking hwestlake19\n",
      "Scraped LD for hwestlake19\n",
      "Checking isidore17\n",
      "Scraped PF for isidore17\n",
      "Scraped LD for isidore17\n",
      "Scraped CX for isidore17\n",
      "Checking isidore18\n",
      "Scraped LD for isidore18\n",
      "Scraped PF for isidore18\n",
      "Scraped CX for isidore18\n",
      "Checking jackhowe17\n",
      "Scraped CX for jackhowe17\n",
      "Scraped PF for jackhowe17\n",
      "Checking jackhowe18\n",
      "Scraped CX for jackhowe18\n",
      "Scraped PF for jackhowe18\n",
      "Checking lex18\n",
      "Scraped LD for lex18\n",
      "Scraped PF for lex18\n",
      "Scraped CX for lex18\n",
      "Checking lex19\n",
      "Scraped LD for lex19\n",
      "Scraped PF for lex19\n",
      "Scraped CX for lex19\n",
      "Checking longhorn17\n",
      "Checking longhorn18\n",
      "Scraped LD for longhorn18\n",
      "Scraped CX for longhorn18\n",
      "Checking loyola17\n",
      "Scraped LD for loyola17\n",
      "Checking loyola18\n",
      "Scraped LD for loyola18\n",
      "Checking marks17\n",
      "Scraped LD for marks17\n",
      "Scraped PF for marks17\n",
      "Checking marks18\n",
      "Scraped LD for marks18\n",
      "Scraped PF for marks18\n",
      "Checking marlborough18\n",
      "Scraped LD for marlborough18\n",
      "Scraped CX for marlborough18\n",
      "Checking marlborough19\n",
      "Scraped CX for marlborough19\n",
      "Scraped LD for marlborough19\n",
      "Checking meadows17\n",
      "Scraped LD for meadows17\n",
      "Scraped CX for meadows17\n",
      "Checking meadows18\n",
      "Scraped LD for meadows18\n",
      "Scraped CX for meadows18\n",
      "Checking milo18\n",
      "Scraped LD for milo18\n",
      "Scraped CX for milo18\n",
      "Checking milo19\n",
      "Scraped LD for milo19\n",
      "Scraped CX for milo19\n",
      "Checking newark18\n",
      "Scraped LD for newark18\n",
      "Scraped CX for newark18\n",
      "Scraped PF for newark18\n",
      "Checking newark19\n",
      "Checking peninsula18\n",
      "Scraped LD for peninsula18\n",
      "Scraped CX for peninsula18\n",
      "Checking peninsula19\n",
      "Scraped LD for peninsula19\n",
      "Scraped CX for peninsula19\n",
      "Checking penn18\n",
      "Scraped CX for penn18\n",
      "Checking penn19\n",
      "Scraped CX for penn19\n",
      "Checking presentation17\n",
      "Scraped LD for presentation17\n",
      "Scraped PF for presentation17\n",
      "Checking presentation18\n",
      "Scraped LD for presentation18\n",
      "Scraped PF for presentation18\n",
      "Checking princeton17\n",
      "Scraped PF for princeton17\n",
      "Scraped LD for princeton17\n",
      "Checking princeton18\n",
      "Scraped PF for princeton18\n",
      "Scraped LD for princeton18\n",
      "Checking ridge17\n",
      "Checking ridge18\n",
      "Scraped LD for ridge18\n",
      "Scraped CX for ridge18\n",
      "Scraped PF for ridge18\n",
      "Checking scarsdale17\n",
      "Checking scarsdale18\n",
      "Scraped LD for scarsdale18\n",
      "Scraped PF for scarsdale18\n",
      "Checking stanford18\n",
      "Scraped LD for stanford18\n",
      "Scraped CX for stanford18\n",
      "Scraped PF for stanford18\n",
      "Checking stanford19\n",
      "Checking strake17\n",
      "Scraped LD for strake17\n",
      "Checking strake18\n",
      "Scraped LD for strake18\n",
      "Checking uk17\n",
      "Scraped LD for uk17\n",
      "Scraped PF for uk17\n",
      "Scraped CX for uk17\n",
      "Checking uk18\n",
      "Scraped LD for uk18\n",
      "Scraped PF for uk18\n",
      "Scraped CX for uk18\n",
      "Checking ups18\n",
      "Scraped PF for ups18\n",
      "Checking ups19\n",
      "Scraped PF for ups19\n",
      "Checking valley17\n",
      "Scraped LD for valley17\n",
      "Scraped CX for valley17\n",
      "Checking valley18\n",
      "Scraped LD for valley18\n",
      "Scraped CX for valley18\n",
      "Checking ward18\n",
      "Scraped LD for ward18\n",
      "Scraped PF for ward18\n",
      "Checking ward19\n",
      "Scraped LD for ward19\n",
      "Scraped PF for ward19\n",
      "Checking yale17\n",
      "Checking yale18\n",
      "Scraped CX for yale18\n",
      "Scraped LD for yale18\n",
      "Scraped PF for yale18\n"
     ]
    }
   ],
   "source": [
    "# read tourn list\n",
    "with open(TOURNAMENT_CSV, 'r') as tourn_file,  open(OUTPATH + \"tab_data.csv\", 'w') as out_file:\n",
    "    \n",
    "    tourn_reader = csv.DictReader(tourn_file)\n",
    "    tournWriter = csv.writer(out_file,\n",
    "                                    lineterminator = \"\\n\")\n",
    "    \n",
    "    tournWriter.writerow([\"Tournament\", \"Event\", \"School\", \"State\", \"Name\", \"Code\", \"Status\"])\n",
    "\n",
    "    for tourn in tourn_reader:\n",
    "        tourn_name = tourn[\"Name\"]\n",
    "        tourn_id = tourn[\"URL\"]\n",
    "        \n",
    "        print(\"Checking \" + tourn_name)\n",
    "            \n",
    "        events = getEvents(tourn_id)\n",
    "\n",
    "        for event in events:\n",
    "\n",
    "            eventType = getType(event[0])\n",
    "                \n",
    "            if eventType in TARGET_EVENTS:\n",
    "                    \n",
    "                eventURL = \"https://www.tabroom.com/\" + event[1]\n",
    "\n",
    "                tournWriter.writerows(getEntries(eventURL, eventType, tourn_name))\n",
    "                    \n",
    "                print(\"Scraped\", eventType, \"for\", tourn_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Judge Scraper\n",
    "\n",
    "#### Collect Links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "paradigm_links = []\n",
    "\n",
    "# iterate through all judges by first name\n",
    "for c in ascii_lowercase:\n",
    "    \n",
    "    url = \"https://www.tabroom.com/index/paradigm.mhtml?search_first={char}&search_last=\".format(char = c)\n",
    "    \n",
    "    # load page\n",
    "    html = urlopen(url).read()\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    \n",
    "    # get all links\n",
    "    links = [link.get(\"href\") for link in soup.find_all(\"a\")]\n",
    "    \n",
    "    # append all paradigm links\n",
    "    paradigm_links += [link for link in links if \"judge_person\" in link]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save judgelinks\n",
    "with open(OUTPATH + \"judgeLinks.txt\", 'w') as outFile:\n",
    "    for link in set(paradigm_links):\n",
    "        outFile.write(link + \"\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Collect Records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "paradigm_links = [name.strip() for name in open(OUTPATH + \"judgeLinks.txt\", 'r')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRecords(url):\n",
    "    # load page\n",
    "    html = urlopen(url).read()\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    name = \" \".join(soup.find(\"span\", {\"class\": \"twothirds\"}).text.strip().split()[:-1])\n",
    "    table = soup.find(\"table\")\n",
    "    \n",
    "    records = []\n",
    "    for row in table.find_all(\"tr\")[1:]:\n",
    "        cols = row.find_all(\"td\")\n",
    "        tourn = cols[0].text.strip()\n",
    "        date = cols[1].text.split()[1]\n",
    "        event = cols[2].text.strip()\n",
    "        roundNum= cols[3].span.text\n",
    "        roundName = cols[3].a.text\n",
    "        aff = cols[4].text.strip()\n",
    "        neg = cols[5].text.strip()\n",
    "        decision = cols[6].text.strip()\n",
    "        panel = cols[7].text.strip()\n",
    "        records.append({\"Judge\" : name,\n",
    "                       \"Tournament\": tourn,\n",
    "                       \"Date\" : date,\n",
    "                       \"Event\" : event,\n",
    "                       \"Round Number\" : roundNum,\n",
    "                       \"Round Name\" : roundName,\n",
    "                       \"Aff\" : aff,\n",
    "                       \"Neg\" : neg,\n",
    "                       \"Decision\" : decision,\n",
    "                       \"Panel\" : panel})\n",
    "        \n",
    "    return records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Broke for https://www.tabroom.com/index/paradigm.mhtml?judge_person_id=36333\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with open(OUTPATH + \"records_2.csv\", 'w') as outFile:\n",
    "    \n",
    "    outWriter  = csv.DictWriter(outFile,\n",
    "                                fieldnames = [\"Judge\",\n",
    "                                            \"Tournament\",\n",
    "                                            \"Date\",\n",
    "                                            \"Event\",\n",
    "                                            \"Round Number\",\n",
    "                                            \"Round Name\",\n",
    "                                            \"Aff\",\n",
    "                                            \"Neg\", \n",
    "                                            \"Decision\",\n",
    "                                            \"Panel\"],\n",
    "                                quotechar='\"', \n",
    "                                quoting=csv.QUOTE_NONNUMERIC,\n",
    "                                lineterminator = \"\\n\")\n",
    "    \n",
    "    outWriter.writeheader()\n",
    "    \n",
    "    count = 0\n",
    "    for link in paradigm_links[10000:20000]:\n",
    "        count += 1\n",
    "        url = \"https://www.tabroom.com/index/\" + link\n",
    "        \n",
    "        try:\n",
    "        \n",
    "            records = getRecords(url)\n",
    "            if (count % 100 == 0):\n",
    "                print(count)\n",
    "            outWriter.writerows(records)\n",
    "        except KeyboardInterrupt:\n",
    "            sys.exit(0)\n",
    "        except:\n",
    "            print(\"Broke for \" + url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
